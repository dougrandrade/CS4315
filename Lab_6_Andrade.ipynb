{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09cde8e8",
   "metadata": {},
   "source": [
    "21 Febuary 2024\n",
    "# <center>Lab 6 Assignment - CS 4315<center>\n",
    "<center>Doug Andrade</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbbe79b",
   "metadata": {},
   "source": [
    "#### 1. Load the SMS file into a `pandas` dataframe using tab delimiters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db9e8f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Pandas module for data frame operations\n",
    "import pandas as pd\n",
    "# Import the Numpy module for \n",
    "import numpy as np\n",
    "\n",
    "# CSV Text file to load\n",
    "csv_file = 'SMSSpamCollection.csv'\n",
    "\n",
    "# Read-in the csv file as a Pandas data frame, as an object to be operated on later\n",
    "spam_df = pd.read_csv(filepath_or_buffer = csv_file, \n",
    "                      sep = '\\t',\n",
    "                      header = 0)\n",
    "\n",
    "spam_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48c2df38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                                SMS\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create binary label version for follow-on correlation analysis (1 = spam)\n",
    "spam_binary = spam_df.copy()\n",
    "spam_binary['Label'] = spam_binary['Label'].replace({'ham': 0, 'spam': 1})\n",
    "\n",
    "spam_binary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f314d3c9",
   "metadata": {},
   "source": [
    "#### 2. Use lemmatization to create count vectors for each SMS message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "171e8307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drandrade/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(stop_words=[&#x27;english&#x27;, &#x27;ha&#x27;, &#x27;le&#x27;, &#x27;wa&#x27;],\n",
       "                tokenizer=&lt;__main__.LemmaTokenizer object at 0x7f35881e2950&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=[&#x27;english&#x27;, &#x27;ha&#x27;, &#x27;le&#x27;, &#x27;wa&#x27;],\n",
       "                tokenizer=&lt;__main__.LemmaTokenizer object at 0x7f35881e2950&gt;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(stop_words=['english', 'ha', 'le', 'wa'],\n",
       "                tokenizer=<__main__.LemmaTokenizer object at 0x7f35881e2950>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import CountVectorizer for conversion of text to a token count matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Import word_tokenize for dividing strings to list of substrings\n",
    "from nltk import word_tokenize\n",
    "# Import WordNetLemmatizer for reducing words to base form\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "# Import search() to search for specific regular expressions\n",
    "from re import search\n",
    "\n",
    "# Create a custom tokenizer with lemmatization\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        # Initialize the word reduction function\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        # Regular expressions filter for numeric characters and short words\n",
    "        regex_num_punctuation = '(\\d+)|([^\\w\\s])'\n",
    "        regex_little_words = r'(\\b\\w{1,2}\\b)'\n",
    "        # Tokenize and lemmatize tokens not in the regular expression filter\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)\n",
    "                if not search(regex_num_punctuation, t) and not \n",
    "                search(regex_little_words, t)]\n",
    "\n",
    "# Initialize the text to token matrix function with lemmatization\n",
    "text2vec_lemma = CountVectorizer(tokenizer = LemmaTokenizer(),\n",
    "                                 stop_words = ['english', 'ha', 'le', 'wa'],\n",
    "                                 lowercase = True)\n",
    "\n",
    "# Apply the text vectorizer and lemmatization to the data frame's \"SMS\" column\n",
    "text2vec_lemma.fit(spam_binary['SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6ebf6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('until', 6106),\n",
       " ('jurong', 3012),\n",
       " ('point', 4273),\n",
       " ('crazy', 1274),\n",
       " ('available', 409)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(text2vec_lemma.vocabulary_.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ce2773",
   "metadata": {},
   "source": [
    "#### 3. Calculate the correlation between each token count and the spam variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d597f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>____</th>\n",
       "      <th>aah</th>\n",
       "      <th>aaniye</th>\n",
       "      <th>aaooooright</th>\n",
       "      <th>aathi</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abeg</th>\n",
       "      <th>...</th>\n",
       "      <th>zed</th>\n",
       "      <th>zero</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>〨ud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 6625 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                                SMS  ____  aah  \\\n",
       "0      0  Go until jurong point, crazy.. Available only ...     0    0   \n",
       "1      0                      Ok lar... Joking wif u oni...     0    0   \n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...     0    0   \n",
       "\n",
       "   aaniye  aaooooright  aathi  abbey  abdomen  abeg  ...  zed  zero  zhong  \\\n",
       "0       0            0      0      0        0     0  ...    0     0      0   \n",
       "1       0            0      0      0        0     0  ...    0     0      0   \n",
       "2       0            0      0      0        0     0  ...    0     0      0   \n",
       "\n",
       "   zindgi  zoe  zogtorius  zoom  zouk  zyada  〨ud  \n",
       "0       0    0          0     0     0      0    0  \n",
       "1       0    0          0     0     0      0    0  \n",
       "2       0    0          0     0     0      0    0  \n",
       "\n",
       "[3 rows x 6625 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforms the fitted count matrix to vector of total count of each token\n",
    "vecs_lemma = text2vec_lemma.transform(spam_binary['SMS'])\n",
    "\n",
    "# Get key (word) form the .vocabulary_ dictionary of key-value pairs\n",
    "keys = list(text2vec_lemma.vocabulary_.keys())\n",
    "# Sort the list of the keys alphabetically\n",
    "keys.sort()\n",
    "\n",
    "# Create a new DataFrame with count vectors and concatenate it with spam_df\n",
    "vecs_df = pd.DataFrame(vecs_lemma.toarray(), \n",
    "                       columns = keys)\n",
    "\n",
    "# Combine the new tokenized vector data frame with the original\n",
    "spam_binary = pd.concat([spam_binary, vecs_df],\n",
    "                        axis = 1)\n",
    "spam_binary.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e971ba94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>____</th>\n",
       "      <th>aah</th>\n",
       "      <th>aaniye</th>\n",
       "      <th>aaooooright</th>\n",
       "      <th>aathi</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abeg</th>\n",
       "      <th>abel</th>\n",
       "      <th>...</th>\n",
       "      <th>zed</th>\n",
       "      <th>zero</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>〨ud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007456</td>\n",
       "      <td>-0.009132</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>-0.012919</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083443</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>0.020351</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>0.034050</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>-0.005272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>____</th>\n",
       "      <td>-0.007456</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000440</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.000359</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aah</th>\n",
       "      <td>-0.009132</td>\n",
       "      <td>-0.000440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.000762</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000762</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.000440</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.000311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaniye</th>\n",
       "      <td>-0.005272</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000440</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000440</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaooooright</th>\n",
       "      <td>-0.005272</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000440</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000440</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6624 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Label      ____       aah    aaniye  aaooooright     aathi  \\\n",
       "Label        1.000000 -0.007456 -0.009132 -0.005272    -0.005272 -0.012919   \n",
       "____        -0.007456  1.000000 -0.000440 -0.000254    -0.000254 -0.000622   \n",
       "aah         -0.009132 -0.000440  1.000000 -0.000311    -0.000311 -0.000762   \n",
       "aaniye      -0.005272 -0.000254 -0.000311  1.000000    -0.000180 -0.000440   \n",
       "aaooooright -0.005272 -0.000254 -0.000311 -0.000180     1.000000 -0.000440   \n",
       "\n",
       "                abbey   abdomen      abeg      abel  ...       zed      zero  \\\n",
       "Label       -0.005272 -0.005272 -0.005272 -0.005272  ...  0.083443 -0.005272   \n",
       "____        -0.000254 -0.000254 -0.000254 -0.000254  ... -0.000622 -0.000254   \n",
       "aah         -0.000311 -0.000311 -0.000311 -0.000311  ... -0.000762 -0.000311   \n",
       "aaniye      -0.000180 -0.000180 -0.000180 -0.000180  ... -0.000440 -0.000180   \n",
       "aaooooright -0.000180 -0.000180 -0.000180 -0.000180  ... -0.000440 -0.000180   \n",
       "\n",
       "                zhong    zindgi       zoe  zogtorius      zoom      zouk  \\\n",
       "Label       -0.005272 -0.005272  0.020351  -0.005272 -0.005272  0.034050   \n",
       "____        -0.000254 -0.000254 -0.000359  -0.000254 -0.000254 -0.000254   \n",
       "aah         -0.000311 -0.000311 -0.000440  -0.000311 -0.000311 -0.000311   \n",
       "aaniye      -0.000180 -0.000180 -0.000254  -0.000180 -0.000180 -0.000180   \n",
       "aaooooright -0.000180 -0.000180 -0.000254  -0.000180 -0.000180 -0.000180   \n",
       "\n",
       "                zyada       〨ud  \n",
       "Label       -0.005272 -0.005272  \n",
       "____        -0.000254 -0.000254  \n",
       "aah         -0.000311 -0.000311  \n",
       "aaniye      -0.000180 -0.000180  \n",
       "aaooooright -0.000180 -0.000180  \n",
       "\n",
       "[5 rows x 6624 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calulate the label column with key word (key)\n",
    "corrs = spam_binary[['Label'] + keys].corr()\n",
    "\n",
    "corrs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e99e91",
   "metadata": {},
   "source": [
    "#### 4. Find the nearest neighbor to \"I know that!\" using Euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b76ae98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the new Pandas dataframe is: (5572, 6624)\n",
      "The shape of the vectorized Numpy array is: (5572, 6623)\n",
      "The shape of the example vector is: (1, 6623)\n"
     ]
    }
   ],
   "source": [
    "# New data frame for nearest neighbor analysis, dropping the \"SMS\" column\n",
    "nn_spam_df = spam_binary.drop(labels = ['SMS'],\n",
    "                              axis = 1,\n",
    "                              inplace = False)\n",
    "\n",
    "# Convert the count vector to a Numpy array\n",
    "vectors = nn_spam_df[nn_spam_df.columns[1:]].to_numpy()\n",
    "# Vectorize the text to analyze, using CountVectorizer\n",
    "example_vec = text2vec_lemma.transform([\"I know that!\"]).toarray()\n",
    "\n",
    "print('The shape of the new Pandas dataframe is: %s\\n\\\n",
    "The shape of the vectorized Numpy array is: %s\\n\\\n",
    "The shape of the example vector is: %s' % (str(nn_spam_df.shape),\n",
    "                                           str(vectors.shape),\n",
    "                                           str(example_vec.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e4292fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nearest Euclidean neighbor to \"I know that!\":\n",
      "ham: \"Ok..\"\n"
     ]
    }
   ],
   "source": [
    "# Calculate Euclidean distances\n",
    "euclid_dist = np.sqrt(np.sum((vectors - example_vec) ** 2,\n",
    "                             axis = 1))\n",
    "\n",
    "# Find the index of the nearest neighbor\n",
    "euclid_idx = np.argmin(euclid_dist)\n",
    "\n",
    "# Find the label of the nearest neighbor\n",
    "euclid_label = spam_df.loc[euclid_idx, 'Label']\n",
    "    \n",
    "# Get the nearest neighbor SMS message\n",
    "euclid_SMS = spam_df.loc[euclid_idx, 'SMS']\n",
    "\n",
    "print('The nearest Euclidean neighbor to \\\"%s\\\":\\n\\\n",
    "%s: \\\"%s\\\"' % (str('I know that!'),\n",
    "               euclid_label,\n",
    "               euclid_SMS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b447a88",
   "metadata": {},
   "source": [
    "#### 5. Finding the nearest neighbor to \"I know that!\" using cosine distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "446a89ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nearest cosine neighbor to \"I know that!\":\n",
      "ham: \"I know that my friend already told that.\"\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "cos_dist = (\n",
    "    (vectors / (norm(vectors, axis = 1) + 1e-10).reshape([-1, 1])) *\n",
    "    (example_vec / norm(example_vec, axis = 1 ))\n",
    ").sum(axis = 1)\n",
    "\n",
    "# Find the index of the nearest neighbor\n",
    "cos_idx = np.argmax(cos_dist)\n",
    "\n",
    "# Find the label of the nearest neighbor\n",
    "cos_label = spam_df.loc[cos_idx, 'Label']\n",
    "\n",
    "# Get the nearest neighbor SMS message\n",
    "cos_SMS = spam_df.loc[cos_idx, 'SMS']\n",
    "    \n",
    "print('The nearest cosine neighbor to \\\"%s\\\":\\n\\\n",
    "%s: \\\"%s\\\"' % (str('I know that!'),\n",
    "               cos_label,\n",
    "               cos_SMS))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
